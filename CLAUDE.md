# DHIS2 Pipelines – Base Rules (PRP / CLAUDE)

> **Default behavior:** Every pipeline MUST ship with a **local DHIS2 (Sierra Leone) test environment** via Docker + a **full test harness** (unit + integration) that runs inside a container based on the OpenHEXA stack. All examples and commands below are normative and should be generated by Claude for every new pipeline.

---

## 1) Scope
- Extract, transform, write, or sync DHIS2 data using OpenHEXA pipelines.
- Pipelines are structured with `@pipeline`, `@task`, `@parameter` decorators only.
- Use `openhexa-toolbox.dhis2` helpers whenever possible (avoid raw HTTP if a helper exists).

---

## 2) Golden Rules
- **No placeholders or TODOs** in delivered code.
- **Parameters** come from OpenHEXA or CLI flags; **no hardcoded secrets/URLs**.
- **Deterministic & testable** code (pure functions where possible, IO behind thin adapters).
- **Dry-run** mode supported for any write operation.
- **Logging** at task boundaries (inputs summary, counts, warnings, errors).

---

## 3) Required Parameters (adapt per pipeline)
```python
@parameter("source_connection", type=DHIS2Connection, required=True)
@parameter("target_connection", type=DHIS2Connection, required=False, description="Required for write/sync")
@parameter("dataset_id", type=str, required=True)
@parameter("period", type=str, description="YYYYMM or YYYYQn, e.g., 2024Q1", required=True)
@parameter("mapping_file", type=File, description="JSON with dataElements & categoryOptionCombos maps", required=True)
@parameter("dry_run", type=bool, default=True)
```
> For extraction-only pipelines, omit unneeded parameters. For sync/write, `target_connection` is required.

---

## 4) Tasks Blueprint (canonical)
1. `validate_connections`
2. `load_and_validate_mappings`
3. `extract_source_data` (or custom query)
4. `validate_org_units` (ensure UIDs exist where required)
5. `transform_data_values` (apply DE/COC mappings)
6. `post_to_target` (import strategy `CREATE_AND_UPDATE`, honor `dry_run`)
7. `generate_summary` (imported/updated/ignored, warnings/errors)

---

## 5) Schemas
**Mapping JSON (example)**
```json
{
  "dataElements": {"SRC_DE": "TGT_DE"},
  "categoryOptionCombos": {"SRC_COC": "TGT_COC"}
}
```
**DHIS2 dataValue (example)**
```json
{"dataElement":"...", "orgUnit":"...", "period":"...", "categoryOptionCombo":"...", "value":"..."}
```

---

## 6) Local Test Environment (MANDATORY)
Every repo MUST include the following files and default commands.

### 6.1 `docker-compose.dhis2.yml`
Brings up **DHIS2 Core** seeded with the **Sierra Leone** demo database.

```yaml
services:
  dhis2:
    image: ${DHIS2_IMAGE:-dhis2/core:40.8.0}
    environment:
      - WAIT_FOR_DB=true
      - JAVA_OPTS=-Xms1g -Xmx2g
      # Seed the Sierra Leone demo DB (adjust version as needed)
      - DHIS2_DB_DUMP_URL=${DHIS2_DB_DUMP_URL:-https://databases.dhis2.org/sierra-leone/2.40/dhis2-db-sierra-leone.sql.gz}
    ports:
      - "8080:8080"        # Web app
    healthcheck:
      test: ["CMD", "wget", "-q", "-S", "http://localhost:8080", "-O", "/dev/null"]
      interval: 20s
      timeout: 5s
      retries: 30
```

### 6.2 `docker/Dockerfile.tests`
Runs tests inside a minimal container that approximates an OpenHEXA environment.

```dockerfile
FROM python:3.11-slim
WORKDIR /workspace

# System deps (add if your pipeline needs them)
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl ca-certificates git && rm -rf /var/lib/apt/lists/*

# Python deps
RUN pip install --no-cache-dir \
    openhexa.sdk openhexa-toolbox pytest pytest-cov ruff mypy

# Copy project
COPY . /workspace

# Default command will run the test suite
CMD ["pytest", "-q"]
```

### 6.3 `.env.example` (checked in)
```
# DHIS2 (local Sierra Leone)
DHIS2_URL=http://localhost:8080
DHIS2_USER=admin
DHIS2_PASS=district
# Optional: tweak versions
DHIS2_IMAGE=dhis2/core:40.8.0
DHIS2_DB_DUMP_URL=https://databases.dhis2.org/sierra-leone/2.40/dhis2-db-sierra-leone.sql.gz
```

### 6.4 `pytest.ini` (optional but recommended)
```ini
[pytest]
addopts = -q -ra
testpaths = pipelines tests
```

### 6.5 `tests/` structure
```
pipelines/<pipeline_name>/
  pipeline.py
  README.md
  requirements.txt
tests/
  conftest.py
  test_mapping_schema.py
  test_transform_unit.py
  test_integration_dry_run.py
docker/
  Dockerfile.tests
docker-compose.dhis2.yml
.env.example
```

**`tests/conftest.py`**
```python
import os
import json
import pytest
from openhexa_toolbox.dhis2 import DHIS2Client

@pytest.fixture(scope="session")
def dhis2_env():
    return {
        "url": os.getenv("DHIS2_URL", "http://localhost:8080"),
        "user": os.getenv("DHIS2_USER", "admin"),
        "password": os.getenv("DHIS2_PASS", "district"),
    }

@pytest.fixture(scope="session")
def dhis2_client(dhis2_env):
    return DHIS2Client(
        base_url=dhis2_env["url"],
        username=dhis2_env["user"],
        password=dhis2_env["password"],
    )

@pytest.fixture
def sample_mapping(tmp_path):
    data = {
        "dataElements": {"SRC_DE": "TGT_DE"},
        "categoryOptionCombos": {"SRC_COC": "TGT_COC"}
    }
    p = tmp_path / "mapping.json"
    p.write_text(json.dumps(data), encoding="utf-8")
    return p
```

**`tests/test_mapping_schema.py`**
```python
import json

def test_mapping_has_required_sections(sample_mapping):
    data = json.loads(sample_mapping.read_text(encoding="utf-8"))
    assert "dataElements" in data and isinstance(data["dataElements"], dict)
    assert "categoryOptionCombos" in data and isinstance(data["categoryOptionCombos"], dict)
```

**`tests/test_transform_unit.py`**
```python
from pipelines.<pipeline_name>.pipeline import apply_mappings  # implement this helper in your code

def test_apply_mappings_transforms_values_correctly():
    value = {
        "dataElement": "SRC_DE",
        "categoryOptionCombo": "SRC_COC",
        "orgUnit": "OU_UID",
        "period": "202401",
        "value": "12"
    }
    mapping = {
        "dataElements": {"SRC_DE": "TGT_DE"},
        "categoryOptionCombos": {"SRC_COC": "TGT_COC"}
    }
    out = apply_mappings(value, mapping)
    assert out["dataElement"] == "TGT_DE"
    assert out["categoryOptionCombo"] == "TGT_COC"
```

**`tests/test_integration_dry_run.py`**
```python
import os
import pytest
from pipelines.<pipeline_name>.pipeline import run_pipeline  # expose a function to call tasks end-to-end

@pytest.mark.integration
def test_pipeline_dry_run_executes_and_reports(dhis2_client, sample_mapping, monkeypatch):
    # Wire environment / parameters
    params = {
        "dataset_id": "DATA_SET_UID",
        "period": "202401",
        "dry_run": True,
        "mapping_file": str(sample_mapping),
    }
    # Inject a fake connection using local DHIS2 client creds (implementation detail up to you)
    monkeypatch.setenv("DHIS2_URL", os.getenv("DHIS2_URL", "http://localhost:8080"))
    monkeypatch.setenv("DHIS2_USER", os.getenv("DHIS2_USER", "admin"))
    monkeypatch.setenv("DHIS2_PASS", os.getenv("DHIS2_PASS", "district"))

    summary = run_pipeline(**params)  # should return a dict-like summary
    # Assertions: adapt to your pipeline's real summary keys
    assert summary["extracted"] >= 0
    assert summary["transformed"] >= 0
    assert "dry_run" in summary and summary["dry_run"] is True
```

---

## 7) Commands (developer quickstart)
```bash
# 1) Start DHIS2 locally (first run may take a while for DB import)
DHIS2_IMAGE=dhis2/core:40.8.0 \
DHIS2_DB_DUMP_URL=https://databases.dhis2.org/sierra-leone/2.40/dhis2-db-sierra-leone.sql.gz \
docker compose -f docker-compose.dhis2.yml up -d

# 2) Build test runner image
docker build -t ohx-tests -f docker/Dockerfile.tests .

# 3) Run tests inside the container (host networking to reach DHIS2:8080)
docker run --rm --network host --env-file .env.example -v "$PWD":/workspace ohx-tests

# (optional) Run a single test file or node-id
docker run --rm --network host --env-file .env.example -v "$PWD":/workspace ohx-tests \
  pytest tests/test_integration_dry_run.py::test_pipeline_dry_run_executes_and_reports -q
```

**Make targets (optional)** — add a `Makefile`:
```makefile
up:
	DHIS2_IMAGE=$${DHIS2_IMAGE:-dhis2/core:40.8.0} \	DHIS2_DB_DUMP_URL=$${DHIS2_DB_DUMP_URL:-https://databases.dhis2.org/sierra-leone/2.40/dhis2-db-sierra-leone.sql.gz} \	docker compose -f docker-compose.dhis2.yml up -d

build-tests:
	docker build -t ohx-tests -f docker/Dockerfile.tests .

test: build-tests
	docker run --rm --network host --env-file .env.example -v "$$PWD":/workspace ohx-tests
```

---

## 8) CI (recommended)
Minimal GitHub Actions workflow (`.github/workflows/tests.yml`):
```yaml
name: tests
on: [push, pull_request]
jobs:
  unit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - run: pip install openhexa.sdk openhexa-toolbox pytest ruff mypy
      - run: ruff check --output-format=github .
      - run: mypy --hide-error-codes --install-types --non-interactive .
      - run: pytest -q -k "not integration"
  integration:
    runs-on: ubuntu-latest
    services:
      dhis2:
        image: dhis2/core:40.8.0
        ports: [ "8080:8080" ]
        env:
          WAIT_FOR_DB: "true"
          DHIS2_DB_DUMP_URL: https://databases.dhis2.org/sierra-leone/2.40/dhis2-db-sierra-leone.sql.gz
        options: >-
          --health-cmd="wget -q -S http://localhost:8080 -O /dev/null" --health-interval=20s --health-timeout=5s --health-retries=30
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - run: pip install openhexa.sdk openhexa-toolbox pytest
      - run: pytest -q -k "integration"
        env:
          DHIS2_URL: http://localhost:8080
          DHIS2_USER: admin
          DHIS2_PASS: district
```

---

## 9) Lint & Types
```bash
ruff check --fix .
mypy .
```

---

## 10) Directory Layout (expected)
```
pipelines/<pipeline_name>/
  pipeline.py
  README.md
  requirements.txt
tests/
  conftest.py
  test_mapping_schema.py
  test_transform_unit.py
  test_integration_dry_run.py
docker/
  Dockerfile.tests
docker-compose.dhis2.yml
.env.example
PRPs/
  <feature>.md
CLAUDE.md or prp_base.md
```

---

## 11) Success Checklist
- [ ] Uses OpenHEXA decorators and toolbox helpers.
- [ ] Mapping & payload schemas validated.
- [ ] Dry-run path implemented and exercised.
- [ ] All tests green locally (Docker) and in CI.
- [ ] `ruff` + `mypy` pass.
- [ ] README documents parameters, mapping schema, and run commands.

---

## 12) Anti-patterns
- Raw `requests` when toolbox has an equivalent.
- Hardcoding dataset/orgUnit/period/URL/credentials.
- Skipping validation/logging.
- Delivering code without tests or without the Docker harness.
